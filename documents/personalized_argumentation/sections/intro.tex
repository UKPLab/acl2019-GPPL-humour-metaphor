\section{Introduction}\label{sec:intro}

We hypothesise that different people find different types of argument more convincing 
than others and therefore, 
textual features have varying levels of importance in determining convincingness, 
depending on the audience. 
We investigate whether certain combinations of textual features are indicative of an argument's convincingness to a particular person.
We hypothesise that predictions of convincingness will be more accurate if we adapt the model to the individual reader based on their previously observed preferences. 
However, preference data for a single individual for any given task can be very sparse, 
so it will be necessary to consider the similarities between different users' preferences.
Furthermore, the  computational cost of learning independent models for each person and each task may be
impractically high, suggesting a need for more efficient approaches that combine information from multiple users.

Our approach is therefore to identify correlations between different people's preferences
so that we can learn shared models of convincingness that can then be adapted to individuals to improve predictions of argument convincingness. 
We aim to establish whether such a model can be learned by observing pairwise convincingness preferences, 
%and whether language features extracted from arguments can further improve performance when which argument a person will find most convincing. 

The experiments evaluate a number of techniques for modelling worker preferences, different types of language features, and the correlations between workers and features. 
We investigate whether workers with similar preferences according to each model give similar justifications for their decisions, thereby lending additional support for models based on correlations between preferences.

We provide a new preference learning model to handle large numbers of potentially very sparse features and large numbers of people. Our Bayesian approach enables us to 
perform automatic feature selection, learn in semi-supervised or unsupervised modes, 
and fully account for model and parameter uncertainty, while scaling to large numbers of input features. 

\section{Related Work}\label{sec:related}

The Gaussian process (GP) preference learning approach of \cite{chu2005preference} resolves such inconsistencies and provides a way to predict rankings or preferences for 
items for which we have not observed any pairwise comparisons based on the item's features. 
An extension to multiple users was proposed by \cite{houlsby2012collaborative}, 
but this method suffered from poor scalability.

Matrix factorisation techniques are commonly used in recommender systems to discover latent
user and item features but can fail if the
data is very sparse unless suitably regularised or given a Bayesian treatment.
Matrix factorisation techniques are also unsuitable for pairwise comparisons as they 
must be learned using explicit numerical ratings.
A more scalable approach that incorporates probabilistic matrix factorisation
(specifically, probabilistic PCA) was proposed by \cite{khan2014scalable}.
Their method is applicable to both pairwise comparisons and ratings data
and as such could be used to learn the model from implicit feedback such as clicks on an item. However, it may be more suitable to use a model for such feedback that explicitly considers the different bias and noise of each type or source of feedback. For such
a purpose, the model of \cite{dawid_maximum_1979} may be appropriate but has to date
been used for classifier combination and categorical labelling tasks in crowdsourcing and has not been applied to preference learning from different types of feedback. 
Bayesian approaches are suited to handling these problems of data sparsity, noise and bias, 
particularly as the modular nature of inference algorithms such as Gibb's sampling and variational approximation is suited to extending the model to handle different types of feedback that give indications of some underlying preferences. 

The GP methods require $\mathcal{O}(P_n)$ steps, where $P_n$ is the number of pairs for 
user $n$. 
The method proposed by \cite{khan2014scalable} reduces this scaling issue by using a random sample of pairs at each iteration of their EM algorithm.
We use SVI to address scalability in a variational Bayesian framework. 
The modular nature of VB allows us to take advantage of models for feedback of different types
where the input values for each type of feedback do not directly correspond (e.g. explicit user ratings and number of clicks may have different values).
By using SVI, we provide a formal way to deal with scalability that comes with guarantees\cite{hoffman2013stochastic}.
We also estimate the output scale of the GPs, the latent factors, and item bias as part of the 
variational approximation. %not clear what the true advantage of this is?

We compare our work on Sushi-A dataset or against the method of \cite{khan2014scalable} to see if 
our modifications are actually useful. 

Factor analysis differs from PPCA in allowing only diagonal noise covariance matrices, making 
the observed variables conditionally independent given the latent variables. It also provides
a probabilistic treatment for inferring the latent features. %are we still using FA?

We also investigate whether argumentation preferences can be reduced to a simpler
clustering structure, which may be easier to learn with very sparse user data.

% possible extension: state variable to describe what was previously seen? This could relate to time 
% since argument seen, and can be converted to an input feature for the GP model: exp(-t). I think
% that learning length scale and output scale for this feature would work.

%%%%% New additions in March 2017 -- edited a little when moved from other paper in August

In most scenarios where we wish to make predictions about arguments, 
there is a very large number of input variables potentially associated with each argument in the dataset,
but very sparse observations of these variables. 
To illustrate this, consider a simple bag-of-words representation of the argument text, and a set
of click-data recording which actions each user took when presented with a choice between different pieces of text. 
Given a large vocabulary, the words present in an argument will be a very small subset of possible words. Users will likely see a subset of texts and the recorded choices will be a much smaller subset of 
the possible combinations of texts. 
To make predictions about unobserved preferences when presented with a new text with sparse data,
we require an abstraction from the raw input data, and thus seek a way to embed the texts into a space 
where texts with similar properties are placed close together. In the case of arguments, one property
that may determine whether texts should be close together is that they have similar levels of 
convincingness to similar types of people, in similar contexts. Our proposal therefore produces
a form of argument embedding, driven by convincingness.
%Other work on argument embeddings was carried out by \cite{???}. 
A similar approach to learning latent features, VBMDS, is proposed by \cite{soh2016distance} for learning embeddings using approximate Bayesian techniques, but does not use the embeddings for 
preference learning to find separate person and item embeddings and does not apply this to NLP problems.
Their proposal does, however, show how to combine points with and without side information -- our
input features -- to make predictions about low-dimensional embeddings for unseen data. 
The kernelized probabilistic matrix factorization (KPMF) \cite{zhou2012kernelized} 
proposes a similar approach to VBMDS using GP priors over latent dimensions, but with a simpler
MAP inference scheme, and different likelihood and distance functions. 
% see section 4.1 in soh2016distance for more related work in this area, such as GPLVM.

An important aspect of convincingness is the context in which an argument is made, particularly
as part of a dialogue. 
In our approach, this context can be represented as input variables that affect the item and person embeddings, where the variables encapsulate the previously seen arguments.
While out-of-scope of the present investigation, future work may investigate the best way to
determine novelty of an argument given a small number of variables representing previously seen arguments.
Another related avenue of improvement is to consider the structure of arguments to select 
argument components -- it may be important to consider not just novelty, but whether claims have 
sufficient support and premises are clearly linked to the claims they support or attack. 
Embedding this structure may require complex graph structures of claims and premises to be represented
as short vectors, and may therefore be a topic of future study. 


% % I think this is future work?
% Secondly, kernel functions are not typically learned
% or adapted to the data, which means that points with different features that commonly co-occur are
% not assigned high covariance, whereas it would be desirable to learn that commonly co-occurring features
% indicate similar target values. 
% A solution to this problem is to represent input features such as words using vectors of continuous values, i.e. word embeddings. This approach was proposed for performing GP regression on 
% text data by \cite{yoshikawa2015non}, who showed how to learn the word embeddings and map document
% distributions over word embeddings to points in a reproducing kernel Hilbert space. 
% % this is what we need for using probabilistic embeddings? Do current probabilistic/Gaussian embeddings
% % just try to infer expected embedding and use it as input to another method? If so, 
% % we could see if there is an improvement in using kernel embeddings of distributions. The kernel
% % embedding is quite simple actually -- just the expectation of the kernel value with respect to the 
% % uncertain variable. The challenge would be to turn this into point value that can be used as 
% % input to a NN that uses no explicit kernel function.... or do they do something equivalent?
% This approach can be used to obtain document embeddings from word embeddings.

% E.g. product review texts. Training data contains +ve reviews with word "good". Unlabelled data
%contains reviews where "good" and "excellent" co-occur --> generative model learns to associate 
%"excellent" with +ve reviews. A GP regression model with "good" and "excellent" as binary input features
% would not be able to learn to associate "excellent" with +ve reviews through co-occurrence, it would 
% rely on "good" being present. 


The latent features allow us to interpolate between items and people in a low-dimensional embedding space. 
A key question in this latent feature approach is how to model the deviation of individual 
preferences from that predicted by latent features common to multiple people (item deviations
can be modelled through an item mean function).
This deviation occurs when there is still entropy in a user's preferences given the latent features
because the latent features only describe patterns that are common to multiple users.
A simple approach is to allow additional noise with uniform variance at each data point, 
so that all preference patterns are represented by the latent feature vectors of items and people.
However, any individual preference patterns particular to one user must then be represented by additional
latent features that are not activated for any other users. 
An alternative is to use a personal model of preference deviation for each person. 
Given the input features of the items and any state variables relating to the person, 
this model can capture correlations in the deviation for different items for the same person. 
Both the latent person features and the individual noise model can also include any input features of 
the person that change over time, e.g. representing their state and the arguments they have 
previously seen. 
This individual noise model allows us to differentiate preference patterns that are specific to 
one user, when the input features may not otherwise be sufficient to distinguish these users. 

Whether an argument is persuasive or not is subjective \cite{lukin2017argument},
hence analysing which arguments a particular person or group of people finds convincing can tell us
about their opinions and influences.
