\section{Identifying Common Patterns of Convincingness}\label{sec:model}

Differences with/notes on Houlsby method:
\begin{itemize}
  \item No common mean
  \item Houlsby uses: w as weights for each user on the D latent functions; w has a GP prior with the user features
  as the input space; 
  in our code, I think we call these weights y just to be confusing;  they use a standard normal noise distribution
  for all users and all items
  \item It seems unnecessary to extend their model with a personal GP over the noise because this could be captured 
  by the latent GPs; therefore it may be better to start with nfactors \leq npeople, then see if the Bayesian shrinkage
  effect reduces the number of active latent functions due to people having common traits; this means we reduce the 
  number of GPs we need
  \item It may also be unecessary to extend their model with a separate noise level per worker because noisiness could also be captured by the noise level of the latent dimensions themselves; however it is possible that allowing
  variations in noise levels could reduce the number of latent factors needed, since we no longer need a latent
  factor to represent noise?
  \item Common means for all workers could be unnecessary, since this too could be captured by a latent factor that
  is shared by most workers; however, if we want to determine the 'consensus' preference, we need to identify this 
  common factor and it may be useful to view the workers as deviating from this underlying mean; this makes the view 
  more similar to CBCC view, where latent factors correspond to community confusion matrices, and user weights 
  correspond to worker community weights; the latent factor GPs model bias in a given community but unlike the CBCC model, they take into account the features of the items; the weights also account for user features when available, unlike CBCC; all modelling of noise, bias levels is then done at community level as in CBCC and individuals are
  described by weights alone.
  \item novelty comes then in using this model for combining preferences from crowdsourcing to infer an underlying consensus or a ground truth (specified by training data in semi-supervised mode) 
  \item experiments therefore need to look at not just predicting individuals' preference labels, but also at
  predicting a ground truth from noisy labels; we continue to use MACE with lots of labels to define ground truth,
  and see what happens when we use only one label per pair
  \item also need to examine differences between results produced by MACE and by collab. pref learning
  \item combining labels does not fit personalisation narrative? Personalised models help correct individual biases
  when inferring ground truth; helps transfer from one person's preferences to a target set of preferences
  \item Thompson sampling for active selection of labels from the crowd? like the crowdsample dataset but we get
  to choose which worker?
  \item Changing the current code: preference components needs to use a single GP with a diagonal covariance 
  and pump the results correctly back into self.f
\end{itemize}


\subsection{Baseline methods}

\begin{itemize}
  \item Random: select a label at random
  \item Most common (MC): select the most common preference label from across the dataset
  \item No differentiation (ND): we do not model differences between workers. Labels are estimated by taking the average of other people's labels for the same preference pair. When there are no previous pairs available, select the most common preference label
  \item Gaussian process preference learning with no differentiation (GP-ND): learn a latent ranking function for the objects from pairwise preferences, ignoring differences between workers and features of the arguments. This provides a probabilistic variant of ND  
\end{itemize}

\subsection{Modelling Correlations Between Individuals}

Two main types of approach:
\begin{itemize}
  \item Factor analysis -- map the set of pairwise preferences to a low-dimensional embedding
  \item Clustering -- assumes that people fall into distinct preference clusters, or can be modelled as a mixture of several archetypes
\end{itemize}

Specific methods to test can be split into several types. First,
we can run different clustering methods on the training data, 
then predict a worker's label by taking the mean of the other cluster members. 
When the no members of the cluster have labelled the pair, we predict using the most common label.
This method is applied to several clustering algorithms:
\begin{itemize}
   \item Affinity propagation (AP-mean)
   \item Gaussian mixture model, using most probable cluster assignment (GMM-mean)
   \item Gaussian mixture model, using cluster assignments weighted by probability (GMM-WM)
\end{itemize}

A similar approach can be taken with dimensionality reduction techniques, where we can use K-nearest neightbours (in this case, few workers label each pair, so we choose k=1 and use MC when no workers have labelled the current instance?):
\begin{itemize}
   \item Factor analysis with K-nearest neighbours (FA-KNN)
\end{itemize}
Alternatively, we can take a weighted average of the other labels for a pair, where the weights are based on inverse distance from the worker in question in the embedded space:
\begin{itemize}
   \item Factor analysis with an inverse distance-weighted mean (FA-weighted)
\end{itemize}
The distance function can be optimised, which leads to proposing more sophisticated methods...

\section{Bayesian Preference Learning Model}

The model introduced in \cite{houlsby2012collaborative} combines preference learning with matrix factorisation 
to identify latent features of items and users that affect their preferences. This allows for a collaborative filtering effect, whereby users with similar preferences on a set of observed items are assumed to have similar 
preferences for other items with similar features. This allows us to make better predictions about the unobserved preferences of a given user when we have seen preferences of a similar user.

The method presented in \cite{houlsby2012collaborative} uses a combination of expectation propagation (EP) and variational Bayes (VB). Since the inference steps require inverting a covariance matrix, this method scales with 
$\mathcal{O}(N^3)$ and is therefore impractical for large datasets. For our modified version of this method, we improve scalability by using stochastic variational inference to infer the complete model. 
The variational approximation to the posterior is given by...

The variational inference algorithm maximises a lower bound on the log marginal likelihood:
\begin{eqnarray}
  \mathcal{L} = \sum_{i=1}^N \mathbb{E}[ \log p(t_i | x_{i,1}, x_{i,2}, \bs f) ] + \nonumber\\
  \sum_{u=1}^U  \mathbb{E}\left[ \log \frac{p(\bs f_u | \bs w \bs y_u, \bs K_{f,u} / s_{f,u} )}{q(\bs f_u)}\right] + \nonumber\\
  \sum_{c=1}^C \mathbb{E}\left[\log\frac{p(\bs w_c | \bs 0, \bs K_w / s_{w,c} ) }{q(\bs w_c) } \right] + \nonumber\\
  \sum_{c=1}^C \mathbb{E}\left[\log\frac{p(\bs y_c | \bs 0, \bs K_y / s_{y,c} ) }{q(\bs y_c) } \right] + \nonumber\\
  \mathbb{E}\left[\log\frac{p(\bs t | \bs \mu, \bs K_{t} / s_t ) }{q(\bs t)} \right] + \nonumber\\
  \sum_{u=1}^U \mathbb{E}\left[\log\frac{p(s_{f,u} | a_{f,u}, b_{f,u})}{q(s_{f,u})}\right] + \nonumber\\
  \sum_{d=1}^D \mathbb{E}\left[\log\frac{p(s_{w,d} | a_{w,d}, b_{w,d})}{q(s_{w,d})}\right] +\nonumber\\
  \sum_{d=1}^D \mathbb{E}\left[\log\frac{p(s_{y,d} | a_{y,d}, b_{y,d})}{q(s_{y,d})}\right] 
\end{eqnarray}
where $t_i$ is the preference label for the $i$th pair, 

To perform feature selection with large numbers of features, we introduce 
an automatic relevance determination
(ARD) approach that uses the gradient of the lower bound on the log marginal likelihood to optimise the kernel length-scales using the L-BFGS-B method\cite{??}. The gradient is given by:
\begin{eqnarray}
\nabla\mathcal{L} = \left[ \frac{\partial \mathcal{L}}{\partial l_{w,1}}, ...,  \frac{\partial \mathcal{L}}{\partial l_{w,D_w}},  \frac{\partial \mathcal{L}}{\partial l_{y,1}}, ...,  \frac{\partial \mathcal{L}}{\partial l_{y,D_y}} \right], &&\\
\frac{\partial \mathcal{L}}{\partial l_{w,d}} = \frac{\partial}{\partial l_{w,d}} 
\sum_{u=1}^U  \mathbb{E}\left[\log\frac{p(\bs f_u | \bs w \bs y_u, \bs K_{f,u} / s_{f,u} )}{q(\bs f_u)}\right] + \nonumber && \\
\sum_{c=1}^C \mathbb{E}\left[\log\frac{p(\bs w_c | \bs 0, \bs K_w / s_{w,c} ) }{q(\bs w_c) } \right] - \nonumber&&\\
\sum_{u=1}^U \mathbb{E}\left[\log q(s_{f,u})\right] - \sum_{d=1}^D \mathbb{E}\left[\log q(s_{w,d})\right] +\nonumber&&\\
= 0.5 (\hat{f}_u - wy_u)^T \bs K_{f,u}^{-1} \frac{\partial \bs K}{\partial \log l_{w,d}} \hat{s}_{f,u} \bs K_{f,u}^{-1} (\hat{f}_u - wy_u) \nonumber\\
- 0.5\mathrm{tr}\left( (\bs K_{f,u}^{-1} - \frac{\bs C^{-1}}{\hat{s}_{f,u}} ) \frac{\partial \bs K_{f,u}}{\partial \log l_{w,d}} \right)\nonumber&&\\
\frac{\partial \mathcal{L}}{\partial l_{y,d}} = &&\\
\end{eqnarray}
where $l_{w,d}$ is a length-scale used for all the GPs over item features. The implicit terms are zero when the VB algorithm has converged.
