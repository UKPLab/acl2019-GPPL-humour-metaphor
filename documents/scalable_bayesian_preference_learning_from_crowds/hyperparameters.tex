\section{Gradient-based Length-scale Optimization}\label{sec:ls}

In the previous sections, we defined preference learning models that 
incorporate GP priors over the latent functions.
The covariances of these GPs are defined by a kernel function $k$, 
typically of the following form:
\begin{flalign}
k_{\bs \theta}(\bs x, \bs x') = \prod_{f=1}^F k_f\left(\frac{|x_f - x_f'|}{l_f}, \bs\theta_f \right)
\textrm{, where } 
\bs \theta = \{l_1,...,l_F, \bs\theta_1,...,\bs \theta_F \}
\label{eq:kernel}
\end{flalign}
where $F$ is the number of features, 
$l_f$ is a length-scale hyper-parameter,
and $\bs \theta_f$ are additional hyper-parameters for an individual 
feature kernel, $k_f$.
Each $k_f$ is a function of the distance between the $f$th feature values in 
feature vectors $\bs x$ and  and $\bs x'$.
The product over features in $k$ means that data points have 
high covariance only if the kernel functions, $k_f$, for all features are high 
(a soft AND operator). 
It is possible to replace the product with a sum, causing covariance to increase
for every $k_f$ that is similar (a soft OR operator),
or other combinations of the individual feature kernels.
The choice of combination over features is therefore an additional hyper-parameter.
% citations? 

The length-scale, $l_f$, controls the smoothness of the function, $k_f$,
across the feature space
and the contribution of each feature to the model. 
If a feature has a large length-scale,
its values, $\bs x$, have less effect on $k_{\bs\theta}(\bs x, \bs x') $
than if it has a shorter length-scale.
Hence, it is important to set $l_f$ to correctly capture feature relevance.
A computationally frugal option is the median heuristic: 
\begin{flalign}
 l_{f,MH} = F \mathrm{median}( \{ |x_{i,f} - x_{j,f}| \forall i=1,..,N, \forall j=1,...,N\} ).
\end{flalign}
The motivation is that the median will normalize the feature, so that features
are equally weighted regardless of their scaling. By using a median to perform this 
normalization, extreme values remain outliers with relatively large distances. 
Multiplying the median by the number of features, $F$,
prevents  the average covariance $k_{\bs \theta}(\bs x, \bs x')$ between items
from increasing as we add more features using the 
product kernel in Equation \ref{eq:kernel}.
This heuristic has been shown to work reasonably well for the task of 
comparing distributions~\citep{gretton2012optimal}, but is a simple heursitic
with no guarantees of optimality. 

An alternative method for setting $l_f$ is Bayesian model selection using 
the type II maximum likelihood method, 
which chooses the value of $l_f$ that 
maximizes the marginal likelihood, $p(\bs y | \bs \theta)$.
Since the marginal likelihoods for our models are intractable, we maximize
the variational lower bound, $\mathcal{L}$, as an approximation (
defined in Equation \ref{eq:lowerbound} for a single user, and Equation \ref{eq:lowerbound_crowd} for the crowd model). 
Optimizing a kernel length-scale in this manner is known as automatic relevance determination (ARD)~\citep{rasmussen_gaussian_2006}, since the optimal
value of $l_f$ depends on the relevance of $f$.

% Removing irrelevant features could improve performance, 
% since it reduces the dimensionality of the space of the preference function.
%A problem when using text data is that large vocabulary sizes and additional linguistic features 
%lead to a large number of dimensions, $D$. 
%The standard maximum likelihood II optimisation requires 
%$\mathcal{O}(D)$ operations to tune each length-scale.
To optimize the length-scales efficiently, we turn to gradient-based methods
 such as L-BFGS-B~\citep{zhu1997algorithm}, which allow us to optimize
 all length-scales simultaneously, rather than one-by-one.
 For the single user model, the required gradient of $\mathcal{L}(q)$
(Equation \ref{eq:lowerbound}) with respect to $l_f$ is as follows:
%Following the derivations in Appendix \ref{sec:vb_eqns}, Equation \ref{eq:gradient_ls},
\begin{flalign}
& \nabla_{l_{\! f}} \mathcal{L} =  
\frac{\partial \mathcal{L}}{\partial \hat{\bs f}_m} \frac{\partial \hat{\bs f}_m}{\partial l_f}
+ \frac{\partial \mathcal{L}}{\partial \bs S} \frac{\partial \bs S}{\partial l_f}
+ \frac{\partial \mathcal{L}}{\partial a} \frac{\partial a}{\partial l_f}
+ \frac{\partial \mathcal{L}}{\partial b} \frac{\partial b}{\partial l_f}
\nonumber \\
 & - \frac{1}{2}\! \bigg \{
 \mathbb{E}[s] \hat{\bs f}_{\! m}^T \bs K_{\! mm}^{-1} 
\frac{\partial \bs K_{\! mm}}{\partial l_f} \bs K_{\! mm}^{-1} \hat{\bs f}_{\! m} 
 + \mathrm{tr}\left(
\mathbb{E}[s]\bs S^T\bs K_{\! mm}^{-1} - \bs I \right)
 \frac{\partial \bs K_{\! mm}}{\partial l_f} \bs K_{\! mm}^{-1}
\! \bigg\}.
\end{flalign}
The first terms in the above equation arise because the parameters of the 
variational parameters depend indirectly on the length-scale. 
However, the partial derivatives of $\mathcal{L}$ with respect to these parameters 
is zero when $\mathcal{L}$ is at a maximum. This occurs when the variational
 inference algorithm has converged, hence these terms can be eliminated if we 
 only compute the gradient $\nabla_{l_{\! f}} \mathcal{L}$ after convergence.
Therefore, we run gradient-based optimization as an outside loop around the 
variational algorithm defined in Section \ref{sec:inf}.
Length-scale optimization begins with an initial guess for $l_f$,
for example, in our experiments, we start with the median heuristic.
Given the current value of $l_f$, the optimizer (e.g. L-BFGS-B)
runs the VB algorithm to convergence, computes 
$\mathcal{L}$ and $\nabla_{l_{\! f}} \mathcal{L}$,
then uses them to propose a new candidate value of $l_f$.
The process repeats until the optimizer converges or reaches a maximum number 
of iterations, and returns the value of $l_f$ that maximized $\mathcal{L}$.

%*** The symbol f should be replaced with \varphi or f? due to clash with function f.

Multi-user model.

Given the kernel function defined in Equation \ref{eq:kernel}, which
contains a product over features,
the partial derivative of the covariance matrix $\bs K_{mm}$ with respect to 
$l_f$ is given by:
\begin{flalign}
\frac{\partial \bs K_{mm}}{\partial l_f} 
& = \frac{\bs K_{mm}}{k_{f}(|\bs x_{mm,f}, \bs x'_{mm,f}) }
\frac{ \bs k_{l_f}(|\bs x_{mm,f}, \bs x'_{mm,f})}{\partial l_f} \nonumber ,\\
\end{flalign}

The choice of kernel function...
In our implementation, we choose the Mat\`ern $\frac{3}{2}$ kernel function for $k$
due to its general properties of smoothness
~\citep{rasmussen_gaussian_2006}... add in citation that shows its good performance.
 
 For the Mat\`ern $\frac{3}{2}$ kernel, the 
 $\frac{\partial \bs K_{l_d}}{\partial l_d}$ is a matrix, where each 
entry, $i,j$,  is defined by:
\begin{flalign}
& \frac{\partial K_{d,ij}}{\partial l_d} = 
\frac{3\bs |\bs x_{i,d} - \bs x_{j,d}|^2}{l_d^3} \exp\left( - \frac{\sqrt{3} \bs |\bs x_{i,d} - \bs x_{j,d}|}{l_d} \right). &
\label{eq:kernel_der}
\end{flalign}
% is defined by Equation \ref{eq:kernel_der}.
% Since we cannot compute $\bs K$ in high dimensions, in practice we substitute $\bs K_{mm}$ for $\bs K$,
% $\bs S$ for $\bs C$, $\hat{\bs f}_{m}$ for $\hat{\bs f}$ and $\bs\mu_{m}$ for $\bs\mu$ so that 

We can define an optimization procedure for the length-scales...
By following the gradients of the length-scale given by 
