\section{Bayesian Preference Learning for Crowds}\label{sec:model}

%%%% Notes

% Title or name of the model: 
% -- cannot decide this until we get most of the paper complete: will emphasis be on crowds? distilling ground truth
% from noisy sources (Bayesian preference learning for fusing unreliable sources)? user preferences/collaborative filtering?
% -- need a new name to differentiate from Houlsby et al. and Khan et al.?
% -- what are the differences in the model? Let's get the model written up.
% -- should also be some buzzword or word to generate interest: 
%    -- 'variational' is on the up, could be used in paper title
%    -- 'stochastic variational' is also on the up
%    -- 'crowdsourcing' on the way down as at 2010 level
%    -- 'gaussian process' on the way up
%    -- 'matrix factorization' kind of on the way up
%    -- 'scalable' on the way up
%    -- 'interactive learning' on the way down
%    -- 'preference learning' flattish, may be on way up slowly
% -- aimed at crowdsourcing problems (uses a common mean function as consensus?)
% -- other parameters for importance of features?
% -- combined preference learning? Preference aggregation? Collaborative crowdsourced preference learning? Bayesian preference learning for crowds? another word for 'multi-user' or 'many users and many items' vs. crowds?

% TO ADD: Why does the variance in f cancel out when predicting the probability of a pairwise label?
% TO ADD: Why does \sigma disappear if we learn the output scale.

% We also estimate the output scale of the GPs, the latent factors, and item bias as part of the 
% variational approximation allowing us to estimate these parameters in a Bayesian manner without 
% resorting to maximum likelihood approaches.

% mention how the noise model deals with inconsistencies in preferences

% \begin{enumerate}
% \item What are the benefits of Bayesian methods and Gaussian processes in particular?
% \item The proposal by \cite{chu2005preference} shows how the advantages of a Bayesian
% approach can be exploited for preference learning by modifying the observation model

% Extensions:
% -- how do we replace the GP with a NN?
% -- would this move us from a Bayesian to an ML solution?
% -- maybe save this for future work? Or add a few lines if we can make it fit with the theme of the paper.
% -- another is to replace the fixed number of clusters with a CRP, then the whole thing can be nonparameteric preference learning with crowds.

\subsection{Modeling Pairwise Preferences}

% Include the case for one user -- preferences may depend on a number of observed features.

% this should be introduced in section 1.
A pairwise comparison between items $i$ and $j$ has a binary label that is either $i \succ j$
if $i$ is preferred to $j$, or $i \prec j$ is $j$ is preferred to $i$.

\subsection{Latent Factors: Bayesian Matrix Factorization}

% 0. Consider multiple users, each with a set of observed features.
% 1. imagine augmenting the observed features with a number of latent features (this is kind of what Khan et al. do)
% 2. imagine that the latent features relate preference function values between items and users using the smallest number of features
% 3. hence the observed features are not needed given the latent features, but we can create a hierarchical model where the latent features depend on the observed ones if available.

\subsection{The complete model}

% joint distribution
% notes about problems with inference.

\subsection{OLD}

%%%% The preference likelihood model

Following Chu and Ghahramani~\citeyear{chu2005preference}, 
we model the relationship between a latent preference function, $f$,
and each observed pairwise label, $v_k \succ u_k$, where $k$ is an index into a list of 
$P$ pairs, as follows:
\begin{flalign}
& p( v_k \succ u_k | f(v_k), f(u_k), \delta_{v_k}, \delta_{u_k} ) & \nonumber\\
& \hspace{1.5cm} = \begin{cases}
 1 & \text{if }f(v_k) + \delta_{v_k} \geq f(u_k) + \delta_{u_k} \\
 0 & \text{otherwise,}
 \end{cases} &
\end{flalign}
where $\delta_i \sim \mathcal{N}(0, 1)$ is Gaussian-distributed noise. 
The noise term allows for variations in the observed preferences, which may occur if 
different annotators disagree or change their minds, or if
the preferences are derived from noisy implicit data such as clicks streams.
We deviate from Chu and Ghahramani~\citeyear{chu2005preference} by assuming $\delta_i$
has variance $\sigma=1$, and instead scale the function $f$ relative to this. This formulation
is equivalent but is more convenient for variational inference. 
We marginalise the noise terms to obtain the preference likelihood:
\begin{flalign}
& p( v_k \succ u_k | f(v_k), f(u_k) ) = \Phi\left( \frac{f(v_k) - f(u_k)}{\sqrt 2} \right), & \label{eq:pl}
\end{flalign}
where $\Phi$ is the cumulative distribution function of a standard Gaussian distribution.
For the latent function , $f$, we assume a Gaussian process prior: $f \sim \mathcal{GP}(0, k_{\theta}/s)$, where 
$k_{\theta}$ is a kernel function with hyper-parameters $\theta$, 
and $s \sim \mathcal{G}(a_0, b_0)$ is an inverse scale parameter %controlling the noise level the level of noise in the function and has 
drawn from a gamma prior with shape $a_0$ and scale $b_0$.
The kernel function controls the correlation between values of $f$ at different points in the feature space.
