\section{Related Work}
\label{sec:rw}

\subsection{Preference Learning from Crowds}

Several works have analyzed bounds on error rates or sample complexity for pairwise 
learning~\citep{chen2015spectral,shah2015estimation}, but do not propose methods
for learning multiple rankings from crowds of users.
% Most approaches use Bradley-Terry or Thurstone. However some also try Mallows models ~\cite
% {busa2014preference,raman2015bayesian} to get the uncertainty over the ranking instead of over a 
% latent score.
% Other approaches use graph-based ranking measures, e.g. based on Kleinberg's HITS ~\citep{sunahase2017pairwise} or PageRank.
% extension of chenc2013 to k-ary preferences. han2018robust
% wang2016blind/Thurstonian Pairwise Preference (TPP): Chen et al. lacks the mechanism to model multiple query domains, (what does this mean? --> better at labeling certain types of items)
%thus incapable to characterize workersâ€™ domain-dependent expertise and truthfulness. 
% CROWD BT does not take query difficulty into account either. (do they have a feature-dependent model?)
% Furthermore, unlike TPP, CROWD BT does not model the generation of rankings (it models generation of pairwise labels directly)
% Therefore, it simplifies the generation of inconsistent annotations as solely a result from worker accuracy
% (it treats differences between workers as pure noise).
~\citet{chen2013pairwise} account for the varying quality of pairwise labels obtained from a crowd
by learning an individual model of agreement with the true pairwise labels for each worker.  
This approach treats the inconsistencies between annotators' labels as noise and does not consider the
items' features. Therefore, this method does not learn the workers' individual preferences
and cannot model how their accuracy depends on the items considered. 
%Say we want to learn a 'ground truth' preference function that may be one user's preference function.
% One set of pairwise labels may be informative for one subset of items.
% E.g. music recommendation, two users may have similar jazz preferences but all other genres are different
% E.g. learning user preferences from webpage clicks, selecting items from a list may be informative in one context and meaningless in another
In contrast, ~\citet{fu2016robust} consider item features when learning to rank from pairwise labels, 
but do not model individual annotators at all.
~\citet{uchida2017entity} do model the confidence of individual annotations
and propose a fuzzy ranking SVM to make predictions given item features. 
However, their approach also assumes a single ranking over items.
The benefit of jointly learning to rank and group items has also been explored\citep{li2018simultaneous}, again assuming a single ordering.

~\citet{tian2012learning} consider crowdsourcing tasks where there may be more than one correct answer.
They use a nonparametric Dirichlet process model to infer a variable number of clusters of answers for each task,
and also infer annotator reliability. 
However, they do not apply the approach to ranking using pairwise labels.
Several other works learn multiple rankings from crowdsourced pairwise labels
rather than a single gold-standard ranking, 
but do not consider the item or user features so cannot extrapolate to new users or 
items~\citep{yi_inferring_2013,kim2014latent,wang2016blind,kim2017latent}. 
Both \citet{yi_inferring_2013} and \citet{kim2017latent} learn a small number of
latent ranking functions that can be combined to construct personalized preferences, 
although neither provide a Bayesian treatment to handle data sparsity.
\citet{wang2016blind} consider the case where different rankings correspond to lists of items
provided in response to search queries. 
While they model the dependence of annotator accuracy on the domain of a query,
their approach was not applied to personal or subjective rankings.
%queries belong to 'domains'. Annotators have different accuracy on each domain. 
% we don't do that because we assume each annotator has their own ranking and so different noise levels are introduced through the personalized preference function having larger values where the annotator is confident. 

% Also consider mentioning relevant work on active learning
% -- finding the most preferred item with minimal labels
% -- learning a preference function using AL
% -- learning within a budget constraint
% Strategy: look at recent works from ML/AI/DM conferences. Must consider annotators with different preferences.
A number of studies consider actively selecting pairs of items for
comparison to minimize the number of pairwise labels required~\citep{radlinski2007active,qian2015learning,maystre2017just,cai2017pairwise}.
Related research treats the selection of pairwise labels as a multi-armed bandit problem~\citep{busa2018preference}.
In this work, we do not study the process of learning from an oracle or user that we can query.
Rather, we develop a model for aggregating pairwise labels from multiple sources, 
which can be used as the basis of active learning methods that exploit the model uncertainty 
estimates provided by this Bayesian approach.

\subsection{Bayesian Preference Learning}

%include the work on collaborative GPPL
A Bayesian approach to preference learning with Gaussian processes, \emph{GPPL}, 
uses item features to can make predictions for unseen items and
share information between similar items~\citep{chu2005preference}.
 This model assumes a single preference function over items, so cannot
be used to model the individual preferences of multiple users.
The approach was extended by ~\citet{houlsby2012collaborative}
to capture individual preferences using a latent factor model. 
Pairwise labels from users with common interests help to predict each other's preference function, hence 
this can be seen as a \emph{collaborative} learning method, as used in \emph{recommender systems}.
The inference techniques proposed for this model mean it scales poorly, with computational complexity $\mathcal{O}(N^3 + NP)$, where $N$ is the number of items and $P$ is the number of pairwise labels, and memory complexity $\mathcal{O}(N^2 + NP + P^2)$. In this paper, we address this issue and adapt the model for aggregating crowdsourced data.

%other Bayesian recommender systems that deal with noisy preferences

\subsection{Bayesian Matrix Factorization}
% previous work on how to make BMF more scalable with larger datasets or Latent factor analysis etc.
% who has used GPs for BMF?

Preference data can be represented as an item-user matrix with $N$ rows and $M$ columns, 
where $N$ is the number of items and $M$ is the number of users.
In this paper, we are interested in the task of predicting values in this matrix
given only sparse observations of pairwise comparisons.
Matrix factorization techniques are commonly used to discover latent user and item features but 
can fail if the data is very sparse, unless suitably regularised or given 
a Bayesian treatment~\citep{salakhutdinov2008bayesian}. 
Recent work on scaling Bayesian matrix factorization (BMF) to large datasets has focused on parallelizing 
inference~\citep{ahn2015large,vander2017distributed,chen2018large}. Instead of distributing the computation,
this paper focuses on reducing the computational cost, although the method we propose is amenable
to parallelization.

 % PCA: Gaussian noise. "The classical PCA converts a set of samples with possibly correlated variables into another   
 % set of samples with linearly uncorrelated variables via an orthogonal transformation [1]. Based on this, PCA
 % is an effective technique widely used in performing dimensionality reduction and extracting features." -- Shi et al 2017. shi2017survey
 % SVD: like PCA with the mean vector set to zeroes.
 % variations of PCA: for handling outliers or large sparse errors
 % most matrix factorizations are special cases of PCA and in practice do not consider the mean vector.
 % probabilistic PCA: latent variables are unit isotropic Gaussians --> all have 0 covariance and 1 variance.
 % Bayesian PCA: places priors on all latent variables.
 % Probabilistic factor analysis: assumes different variances on each of the latent factors.
 % Probabilistic matrix factorisation: ignores the mean. --> I.e. can be done with SVD
 % I think this means our method is a form of PFA? But extended to consider correlations in the weights.
 % NMF: as matrix factorisation but the low-rank matrices are non-negative.
Several extensions of BMF use Gaussian process priors over latent factors 
to model correlations between 
items given side information or observed item features~\citep{adams2010incorporating,zhou2012kernelized,houlsby2012collaborative,bolgar2016bayesian}. 
However, these techniques are not directly applicable to 
learning from pairwise comparisons 
as they assume that the observations are Gaussian-distributed numerical ratings~\citep{shi2017survey}. 

To combine Bayesian matrix factorization with a pairwise likelihood,
~\citet{houlsby2012collaborative} propose a combination of expectation propagation and variational Bayesian inference.
However, their proposed method does not scale sufficiently to the numbers of 
items, users or pairwise labels found in many important application domains. 
% of their hybrid inference method expectation propagation and variational Bayes limits its application in many domains.
% They use FITC to provide a sparse approximation. This is still not as scalable as SVI and doesn't work as well --
% see the Hensman papers?
In contrast, ~\citet{khan2014scalable} develop a scalable variational EM algorithm
for matrix factorization but combine this with a separate GP to model each user's preferences. 
%with Gaussian processes to improve performance with sparse data. 
%Their model can be learned using pairwise labels, numerical ratings, or other likelihoods.
However, while the proposed method can be trained with pairwise labels, 
it does not capture correlations between items or users in the latent factors.
%user features nor model dependencies between item features 
%and the low-dimensional latent features, so it cannot exploit the latent features to predict preference scores for new items and relies instead on a user-specific GP.
%In contrast, our approach does not require learning a separate GP per user, but instead
%places GPs on both the latent factors. This means that the item and user
%features assist in learning the latent factors as we can exploit their similarities and
%correlations.
%relying instead on a purely individual GP with no shared information,
%(this would be a problem if the user fits the latent features exactly as the GP will end up modelling the user's individual devaiation from the common preferences modeled by the latent features) 
Furthermore, their scalable inference method sub-samples training data rather than learning from the complete training set.
%To achieve scalability using a variational EM algorithm, ~\citet{khan2014scalable}
%sub-sample the pairwise labels meaning that 
%some training data must be discarded. In this paper, we
%applies stochastic variational inference to learn from all data 
%while limiting memory and computational requirements.
% how do we compare to them or do we get out of it? --> compare results on the same datasets
%Our approach is similar to Khan et al. 2014. "Scalable Collaborative Bayesian Preference Learning" but differs in that
%we also place priors over the weights and model correlations between different items and between different people.
%Our use of priors also encourage sparseness in the features. 
%TODOs:
% what is meant by 'factorization assumptions' exactly and do we make them? I think we do but don't fully
% understand why they're so bad. See [18,11] from Khan for examples of bad factorization. 

\subsection{Stochastic Variational Inference}
% use of SVI for making Bayesian methods more scalable, including GPs
% To the best of our knowledge, SVI has not previously been applied to BMF
Models that combine Gaussian processes with non-Gaussian likelihoods require approximate inference
methods that often scale poorly with the amount of training data available. 
This problem can be tackled using \emph{Stochastic variational inference (SVI)}~\citep{hoffman2013stochastic}. 
SVI has been successfully applied to Gaussian processes~\citep{hensman2013gaussian}, including Gaussian process classifiers~\citep{hensman2015scalable}, and Gaussian process preference learning (GPPL)~\citep{simpson2018finding}.
This paper adapts SVI to Bayesian matrix factorization for the first time as part of a solution for
collaborative preference learning. 
We also provide the first full derivation of SVI for GPPL
and introduce a technique for efficiently tuning the length-scale hyper-parameters of the Gaussian processes.
